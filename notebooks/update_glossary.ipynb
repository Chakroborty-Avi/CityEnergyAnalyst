{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Update glossary.csv file using data from schemas.yml"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": "import cea.scripts\nimport cea.inputlocator\nimport cea.config\nimport cea.glossary\nfrom cea.tests.trace_inputlocator import get_csv_schema\nimport os\nimport yaml\nimport json"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": "schemas = cea.scripts.schemas()\nglossary_df = cea.glossary.read_glossary_df()\nlocators = schemas.keys()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### start by finding all entries in schemas.yml without a schema"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "the following three locator methods need \"special\" treatment:\n- get_optimization_checkpoint\n  - \"special\" schema\n- get_optimization_disconnected_cooling_capacity\n  - only present in projects with cooling network\n- get_optimization_connected_cooling_capacity\n  - only present in projects with cooling network\n  \nthis code assumes you have a \"reference-case-cooling/baseline\" in your projectroot and have run the optimization on that (e.g. run `cea workflow --workflow district-cooling-system`)"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": "config = cea.config.Configuration()\nconfig.scenario = os.path.join(config.project, \"..\", \"reference-case-cooling\", \"baseline\")\nlocator = cea.inputlocator.InputLocator(scenario=config.scenario)\n\n# load get_optimization_checkpoint schema\nif not schemas[\"get_optimization_checkpoint\"][\"schema\"]:\n    with open(locator.get_optimization_checkpoint(1), 'r') as fp:\n        get_optimization_checkpoint = json.load(fp)\n    schemas[\"get_optimization_checkpoint\"][\"schema\"] = {\n        str(key): {\"sample_data\": get_optimization_checkpoint[key],\n                   \"types_found\": None}\n        for key in get_optimization_checkpoint.keys()\n    }\n\n# load get_optimization_disconnected_cooling_capacity schema\nif not schemas[\"get_optimization_disconnected_cooling_capacity\"][\"schema\"]:\n    schemas[\"get_optimization_disconnected_cooling_capacity\"][\"schema\"] = get_csv_schema(\n        locator.get_optimization_disconnected_cooling_capacity(1, 1))\n    \n# load get_optimization_connected_cooling_capacity schema\nif not schemas[\"get_optimization_connected_cooling_capacity\"][\"schema\"]:\n    schemas[\"get_optimization_connected_cooling_capacity\"][\"schema\"] = get_csv_schema(\n        locator.get_optimization_disconnected_cooling_capacity(1, 1))"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": "# each locator method needs a \"schema\" entry (this should not output anything)\nfor lm in locators:\n    if not \"schema\" in schemas[lm]:\n        print lm"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": "# the \"schema\" entry should not be `None` (this should not output anything)\nfor lm in locators:\n    if not schemas[lm][\"schema\"]:\n        print lm"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "if any of the above produce printed output, update schemas.yml and re-run the notebook"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### make sure the \"used-by\" and \"created-by\" lists don't contain duplicates"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": "for lm in locators:\n    if not \"used_by\" in schemas[lm]:\n        print lm"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": "for lm in locators:\n    if not \"created_by\" in schemas[lm]:\n        print lm"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "each locator should have a \"used_by\" and a \"created_by\" - let's assume they're all lists"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": "for lm in locators:\n    schemas[lm][\"used_by\"] = sorted(set(schemas[lm][\"used_by\"]))\n    schemas[lm][\"created_by\"] = sorted(set(schemas[lm][\"created_by\"]))"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "saving to: c:\\users\\darthoma\\documents\\github\\cityenergyanalyst\\cea\\schemas.yml\n"
    }
   ],
   "source": "# save it back\nschemas_yml = os.path.join(os.path.dirname(cea.scripts.__file__), 'schemas.yml')\nprint \"saving to:\", schemas_yml\nwith open(schemas_yml, 'w') as fp:\n    yaml.dump(schemas, fp)\nschemas = cea.scripts.schemas()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### find all schema entries that are not in glossary.csv"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### find all glossary entries that are not in schemas.yml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
